python train.py -c D:\GoogleDrive\datasets\kitti\TrianFlow\config\kitti.yaml --gpu 0 --mode flow --prepared_save_dir data_train\kitti_2011_09_26 --model_dir D:\GoogleDrive\datasets\trianflow_weights\try

# evaluate
python test.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\kitti-PC.yaml --gpu 0 --mode flow_3stage --task kitti_flow --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth --result_dir D:\GoogleDrive\datasets\trianflow_weights\results\flow2015-210209
CONFIG: D:\GoogleDrive\datasets\kitti\TrianFlow\config\kitti-PC.yaml, mode: flow_3stage
[EVAL] [KITTI 2015]
       epe,    epe_noc,    epe_occ,   epe_move, epe_static, move_err_rate, static_err_rate,   err_rate
    5.7566,     3.2819,    16.5561,     8.8268,     5.2342,     0.2725,     0.1923,     0.2074

##python infer_vo.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\odo-PC.yaml --gpu 0 --traj_save_dir_txt D:\Datasets\kitti\dataset\sequences\traj_save --sequences_root_dir D:\Datasets\kitti\dataset\sequences --sequence 01 --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth
python infer_vo.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\odo-PC.yaml --gpu 0 --traj_save_dir_txt D:\Datasets\kitti\dataset\sequences\traj_save --sequences_root_dir D:\Datasets\kitti\dataset\sequences --sequence 00 --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth
python .\core\evaluation\eval_odom.py --gt_txt [path\to\your\groundtruth\poses\txt] --result_txt [path\to\your\prediction\txt] --seq [sequence id to evaluate]

=====================================================================

only colored left image is used
for kitti 2012, it should be 'color_0'
for kitti 2015, it should be 'image_02'
dataset(只?)用到image_02\data

'calib' for kitti 2012
'calib_cam_to_cam' for kitti 2015

train.py
    #ln81 kitti_raw_dataset.prepare_data_mp(data_dir, stride=1)
kitti_raw.py
        #ln74 def prepare_data_mp(self, output_dir, stride=1):
        #ln78 static_frames = self.collect_static_frame()
            # ln54 def collect_static_frame(self):
        # ln109 p = mp.Process(target=process_folder, args=(q, static_frames, test_scenes, self.data_dir, output_dir, stride))
            # ln8 def process_folder(q, static_frames, test_scenes, data_dir, output_dir, stride=1):
    #ln92 dataset = KITTI_Prepared(data_dir, num_scales=cfg.num_scales, img_hw=cfg.img_hw, num_iterations=(cfg.num_iterations - cfg.iter_start) * cfg.batch_size)
    #ln102         gt_flows_2012, noc_masks_2012 = load_gt_flow_kitti(cfg.gt_2012_dir, 'kitti_2012')
core\evaluate_flow.py
                    #ln60 def load_gt_flow_kitti(gt_dataset_dir, mode):
                        #ln74 fun = functools.partial(read_flow_gt_worker, dir_gt)
                            #ln53 def read_flow_gt_worker(dir_gt, i):
train.py

<<<<<<< Updated upstream
=======
# ln132 loss_pack = model(inputs)
model_flow.py
    ln319     def forward(self, inputs, output_flow=False, use_flow_loss=True):
        #ln330         feature_list_1, feature_list_2 = self.fpyramid(img1), self.fpyramid(img2)
            #ln154         self.fpyramid = FeaturePyramid()
        ln335 img2_visible_masks, img1_visible_masks = self.get_visible_masks(optical_flows, optical_flows_rev)
        ln185     def get_visible_masks(self, optical_flows, optical_flows_rev):
            ln191 img2_visible_masks.append(self.get_occlusion_mask_from_flow(shape, optical_flow))
            ln169 def get_occlusion_mask_from_flow(self, tensor_size, flow):
                ln172         occ_mask = transformerFwd(mask.permute(0,2,3,1), flow.permute(0,2,3,1), out_size=[h,w]).permute(0,3,1,2)
                ln12 def transformerFwd(
                    ln147 output = _transform(flo, U, out_size)
                    ln119     def _transform(flo, input_dim, out_size):
                        #ln127 x_s, y_s = _meshgrid(out_height, out_width)
                        #ln111     def _meshgrid(height, width):
                    ln140         input_transformed = _interpolate(input_dim, x_t_flat, y_t_flat, out_size)
                    ln38     def _interpolate(im, x, y, out_size):
                        

core/networks/structures/
FeaturePyramid - feature_pyramid.py
    12层，输出偶数层的结果(共6层)
PWC_tf - pwc_tf.py
(adopted from PWC-Net)
    * correlation: 将两张feature map进行相关性计算
    * warp: 在第l层，我们使用第l+1层的2倍上采样流将img2的特征向img1扭曲
>>>>>>> Stashed changes
