python train.py -c D:\GoogleDrive\datasets\kitti\TrianFlow\config\kitti.yaml --gpu 0 --mode flow --prepared_save_dir data_train\kitti_2011_09_26 --model_dir D:\GoogleDrive\datasets\trianflow_weights\try

# evaluate
python test.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\kitti-PC.yaml --gpu 0 --mode flow_3stage --task kitti_flow --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth --result_dir D:\GoogleDrive\datasets\trianflow_weights\results\flow2015-210209
CONFIG: D:\GoogleDrive\datasets\kitti\TrianFlow\config\kitti-PC.yaml, mode: flow_3stage
[EVAL] [KITTI 2015]
       epe,    epe_noc,    epe_occ,   epe_move, epe_static, move_err_rate, static_err_rate,   err_rate
    5.7566,     3.2819,    16.5561,     8.8268,     5.2342,     0.2725,     0.1923,     0.2074

##python infer_vo.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\odo-PC.yaml --gpu 0 --traj_save_dir_txt D:\Datasets\kitti\dataset\sequences\traj_save --sequences_root_dir D:\Datasets\kitti\dataset\sequences --sequence 01 --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth
python infer_vo.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\odo-PC.yaml --gpu 0 --traj_save_dir_txt D:\Datasets\kitti\dataset\sequences\traj_save\00.txt --sequences_root_dir D:\Datasets\kitti\dataset\sequences --sequence 00 --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth
python .\core\evaluation\eval_odom.py --gt_txt D:\Datasets\kitti\dataset\sequences\00\poses.txt --result_txt D:\Datasets\kitti\dataset\sequences\traj_save\00.txt --seq 00

python infer_vo.py --config_file D:\GoogleDrive\datasets\kitti\TrianFlow\config\odo-NTU-PC.yaml --gpu 0 --traj_save_dir_txt D:\GoogleDrive\datasets\Pioneer\NTU\traj_save\DJI_0017.txt --sequences_root_dir D:\Datasets\Pioneer\dataset\sequences --sequence DJI_0017 --pretrained_model D:\GoogleDrive\datasets\kitti\TrianFlow\kitti_odo.pth
python .\core\evaluation\eval_odom.py --gt_txt D:\Datasets\kitti\dataset\sequences\00\poses.txt --result_txt D:\Datasets\kitti\dataset\sequences\traj_save\00.txt --seq 00

=====================================================================

only colored left image is used
for kitti 2012, it should be 'color_0'
for kitti 2015, it should be 'image_02'
dataset(只?)用到image_02/data

'calib' for kitti 2012
'calib_cam_to_cam' for kitti 2015

train.py
    #ln81 kitti_raw_dataset.prepare_data_mp(data_dir, stride=1)
kitti_raw.py
        #ln74 def prepare_data_mp(self, output_dir, stride=1):
        #ln78 static_frames = self.collect_static_frame()
            # ln54 def collect_static_frame(self):
        # ln109 p = mp.Process(target=process_folder, args=(q, static_frames, test_scenes, self.data_dir, output_dir, stride))
            # ln8 def process_folder(q, static_frames, test_scenes, data_dir, output_dir, stride=1):
    #ln92 dataset = KITTI_Prepared(data_dir, num_scales=cfg.num_scales, img_hw=cfg.img_hw, num_iterations=(cfg.num_iterations - cfg.iter_start) * cfg.batch_size)
    #ln102         gt_flows_2012, noc_masks_2012 = load_gt_flow_kitti(cfg.gt_2012_dir, 'kitti_2012')
core/evaluate_flow.py
                    #ln60 def load_gt_flow_kitti(gt_dataset_dir, mode):
                        #ln74 fun = functools.partial(read_flow_gt_worker, dir_gt)
                            #ln53 def read_flow_gt_worker(dir_gt, i):
train.py
#TODO ln120 eval_2012_res = test_kitti_2012(cfg, model_eval, gt_flows_2012, noc_masks_2012)

# ln132 loss_pack = model(inputs)
model_flow.py
    ln319     def forward(self, inputs, output_flow=False, use_flow_loss=True):
        #ln330         feature_list_1, feature_list_2 = self.fpyramid(img1), self.fpyramid(img2)
            #ln154         self.fpyramid = FeaturePyramid()
        #ln335 img2_visible_masks, img1_visible_masks = self.get_visible_masks(optical_flows, optical_flows_rev)

        ln12 def transformerFwd(
            ln147 output = _transform(flo, U, out_size)
                ln127 x_s, y_s = _meshgrid(out_height, out_width)
                    #ln111     def _meshgrid(height, width):


# ln132 loss_pack = model(inputs)
model_flow.py
    ln319     def forward(self, inputs, output_flow=False, use_flow_loss=True):
        #ln330         feature_list_1, feature_list_2 = self.fpyramid(img1), self.fpyramid(img2)
            #ln154         self.fpyramid = FeaturePyramid()
        #ln335 img2_visible_masks, img1_visible_masks = self.get_visible_masks(optical_flows, optical_flows_rev)
        #ln185     def get_visible_masks(self, optical_flows, optical_flows_rev):
            #ln191 img2_visible_masks.append(self.get_occlusion_mask_from_flow(shape, optical_flow))
            #ln169 def get_occlusion_mask_from_flow(self, tensor_size, flow):
                #ln172         occ_mask = transformerFwd(mask.permute(0,2,3,1), flow.permute(0,2,3,1), out_size=[h,w]).permute(0,3,1,2)
                #ln12 def transformerFwd(
                    #ln147 output = _transform(flo, U, out_size)
                    #ln119     def _transform(flo, input_dim, out_size):
                        #ln127 x_s, y_s = _meshgrid(out_height, out_width)
                        #ln111     def _meshgrid(height, width):

                        #ln140         input_transformed = _interpolate(input_dim, x_t_flat, y_t_flat, out_size)
                        #(skipped) ln38     def _interpolate(im, x, y, out_size):
        #ln337         img2_consis_masks, img1_consis_masks, fwd_flow_diff_pyramid, bwd_flow_diff_pyramid = self.get_consistent_masks(optical_flows, optical_flows_rev)
        #ln195     def get_consistent_masks(self, optical_flows, optical_flows_rev):
            #ln201             bwd2fwd_flow = warp_flow(optical_flow_rev, optical_flow)
net_utils.py
            #ln16 def warp_flow(x, flow, use_mask=False):
        #ln367         loss_pack['loss_pixel'] = self.compute_loss_pixel(img1_pyramid, img1_warped_pyramid, img1_valid_masks) + \
        #ln235     def compute_loss_pixel(self, img_pyramid, img_warped_pyramid, occ_mask_list):

        ln369 loss_pack['loss_ssim'] = self.compute_loss_ssim(img1_pyramid, img1_warped_pyramid, img1_valid_masks) + \
        ln246     def compute_loss_ssim(self, img_pyramid, img_warped_pyramid, occ_mask_list):
            ln252             ssim = SSIM(img * occ_mask_pad, img_warped * occ_mask_pad)
ssim.py     ln4 def SSIM(x, y):
        ln371 loss_pack['loss_flow_smooth'] = self.compute_loss_flow_smooth(optical_flows, img1_pyramid) + \
        ln275     def compute_loss_flow_smooth(self, optical_flows, img_pyramid):



core/networks/structures/
FeaturePyramid - feature_pyramid.py
    12层，输出偶数层的结果(共6层)
PWC_tf - pwc_tf.py
(adopted from PWC-Net)
    * correlation: 将两张feature map进行相关性计算
    * warp: 在第l层，我们使用第l+1层的2倍上采样流将img2的特征向img1扭曲